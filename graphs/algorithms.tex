\chapter{Алгоритми върху графи}

\section{Защо изобщо се занимаваме с графи?}

Графите са може би най-приложимата структура в областта на компютърните науки.
Тяхната моделираща мощ е несравнима с тази на останалите структури.
Те могат се използват за моделиране на:
\begin{itemize}
    \item приятелски връзки в социални мрежи;
    \item пътни мрежи в навигационни системи;
    \item йерархични системи;
    \item биологични мрежи.
\end{itemize}
Някои от задачите, които могат да решават са:
\begin{itemize}
    \item намиране на най-къс път от точка $A$ до точка $B$;
    \item намиране на съвместима наредба на дадени задачи;
    \item намиране на най-добро разписание на полети;
    \item класифициране на уебсайтове по популярност;
    \item маркетинг в социални мрежи;
    \item валидация на текст.
\end{itemize}

\section{Как представяме графите в паметта?}

В зависимост от нашите цели графите могат да бъдат представени в паметта по различни начини.
Най-използваните начини са:
\begin{itemize}
    \item \textbf{Списък на съседство}:

          За всеки връх се пазят в списък съседите му (и теглата ако има такива).
    \item \textbf{Матрица на съседство}:

          Пази се булева (може и числова ако графът е тегловен) таблица със всевъзможните комбинации от двойки върхове.
          Ако между два върха има ребро, то в съответната клетка пише единица (или теглото на реброто при тегловен граф), иначе нула.
    \item \textbf{Списък с ребрата}:

          Множеството от ребра идва като списък. Обикновено ако графът е неориентиран се пази само една пермутация на реброто.
\end{itemize}

Матрицата на съседство се използва по-рядко.
Този подход е добър, когато графите са гъсти т.е. има много ребра в тях.
В противен случай ние заемаме много повече памет от колкото ни е нужна.
За сметка на това можем да проверим дали между два върха има ребро за константно време.

Списъците на съседство са по-пестеливи от към памет в средния случай, обаче за сметка на това по-бавно се проверява съседство между два върха.
Този подход е добър, когато графите са редки т.е. имат малко ребра в тях.
Също така ако по някаква причина ни трябва да изброяваме точно съседите на някакъв връх (да кажем за някакво обхождане), това очевидно е най-добрият начин.
В най-лошия случай заемаме двойно повече памет от подхода с матрицата.

Списъка с ребрата е най-пестеливия начин от тези три.
Пази се минималното количество нужна информация.
Проблемът тук е, че проверката за съседство и изброяването на съседи на даден връх са бавни.
Обаче това представяне все пак се използва, например когато искаме да построим МПД.
Накратко, сложностите са такива:
\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        подход               & памет           & $(u, v) \in E$ & изброяване на съседите \\
        \hline
        списък на съседство  & $O(|V| + |E|)$  & $O(|V|)$       & $\Theta(|N(v)|)$       \\
        \hline
        матрица на съседство & $\Theta(|V|^2)$ & $\Theta(1)$    & $\Theta(|V|)$          \\
        \hline
        списък с ребра       & $\Theta(|E|)$   & $O(|E|)$       & $\Theta(|E|)$          \\
        \hline
    \end{tabular}
\end{center}

\section{Код на алгоритмите за обхождане на графи}

Първият алгоритъм, за обхождане в широчина, е ``по-предпазлив''.
Той обхожда върховете на слоеве, започвайки с някакъв първоначален връх на слой $0$.
Намирайки се в слой $k$, ако преминем с ребро до необходен връх, ще се озовем в слой $k + 1$:
\lstinputlisting{algorithms/bfs.txt}

Сложност на алгоритъма за търсене в широчина в най-лошия случай:
\begin{itemize}
    \item по време -- $\Theta(|V| + |E|)$;
    \item по памет -- $\Theta(|E|)$.
\end{itemize}

Тук виждаме силата на представянето чрез списъци на съседство.
Ако например тук бяхме използвали матрица на съседство, алгоритъмът ни винаги щеше да има сложност $\Theta(|V|^2)$.

Нека сега разгледаме другия алгоритъм -- за обхождане в дълбочина.
Тук гледаме да влизаме колкото се може ``по-надълбоко'' в даден връх т.е. избираме произволно ребро в текущ връх докато можем, и след това се връщаме на предния и правим същото:

\lstinputlisting{algorithms/dfs.txt}

Сложността по време и памет на алгоритъма за търсене в дълбочина е същата като на този за търсене в широчина.

\newpage

\section{Най-къси пътища в тегловен граф}

Започваме с може би най-известния нетривиален графов алгоритъм -- алгоритъмът на Дийкстра за намиране на най-къси пътища в тегловен граф.
При него започваме с един стартов връх, и намираме най-късите пътища между този стартов връх и всеки достижим от него.

Ето как става това:
\lstinputlisting{algorithms/dijkstra.txt}
Алгоритъмът има сложност по време $\Theta((|V| + |E|)\log(|V|))$ в най-лошия случай.

\section{Структурата Union-find/Disjoint-union}

Ще разгледаме метод за поддържане на разбиване на множества от вида $\{ 1, \dots, n \}$.
Искаме да започнем от разбиването $\{ \{ 1 \}, \dots, \{ n \} \}$, и след това бързо да можем да обединяваме множества и да проверяваме дали някои $i, j$ попадат на едно и също място в разбиването.
За да може тези проверки и сливания да стават бързо, се използва структурата Union-find (понякога се нарича Disjoint-union).
Ще имаме единствена функция $\operatorname{unify}(i, j)$, която приема $i, j \in \{ 1, \dots, n \}$ и слива множествата от разбиването, в които $i$ и $j$ участват.
Ако преди това те са били в едно и също множество, то тогава накрая връщаме $\F$, иначе връщаме $\T$.

Имплементацията е следната:
\lstinputlisting{structures/union_find.txt}
Сложността на извикването на $\operatorname{unify}$ е $O(\alpha(n))$, където $\alpha$ е обратната функция на Акерман.
Тази функция расте изключително бавно -- $\alpha(n) \leq 4$ за $n < 10^{600}$.

\newpage

\section{Алгоритъмът на Крускал за намиране на МПД}

Алгоритъмът на Крускал работи по много естествен начин.
Стараем се да приоритизираме ребрата с най-малки тегла.
Не да ги добавяме само ако биха образували цикъл.

Нека сега формализираме разсъжденията си.
Даден тегловният граф $G = (V, E, w)$.
Него ще пазим като масив от ребра $T[1 \dots k] \in \operatorname{arr}(E)$.
Сега дефинираме релацията $\leq_G \subseteq E \cross E$ така:
\[
    e_1 \leq_G e_2 \stackrel{def}{\iff} w(e_1) \leq w(e_2).
\]

Вече можем да преминем на имплементацията:
\lstinputlisting{algorithms/kruskal.txt}
Сложността на алгоритъма по време е $\Theta(|E|\log(|E|))$ в най-лошия случай.