\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english, bulgarian]{babel}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{hyperref, fancyhdr, lastpage, fancyvrb, tcolorbox, titlesec}
\usepackage{array, tabularx, colortbl}
\usepackage{tikz}
\usepackage{venndiagram}
\usepackage{amsthm, bm}
\usepackage{relsize}
\usepackage{amsmath,physics}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{theoremref}
\usepackage{circuitikz}
\usepackage[a4paper, left=0.50in, right=0.50in, top=0.5in, bottom=1.0in]{geometry}
\usepackage{stmaryrd}
\usepackage[symbol]{footmisc}

\pgfplotsset{width=10cm,compat=1.9}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\F}{\mathcal{F}}

\ExplSyntaxOn
\NewDocumentCommand{\opair}{m}
{
  \langle\mspace{2mu}
  \clist_set:Nn \l_tmpa_clist { #1 }
  \clist_use:Nn \l_tmpa_clist {,\mspace{3mu plus 1mu minus 1mu}\allowbreak}
  \mspace{2mu}\rangle
}
\ExplSyntaxOff

\hypersetup{
  colorlinks=true,
  linktoc=all,
  linkcolor=blue
}

\theoremstyle{definition}
\newtheorem{definition}{Дефиниция}[section]
\newtheorem*{warning}{\textcolor{red}{Внимание}}
\theoremstyle{plain}
\newtheorem{theorem}[definition]{Теорема}
\newtheorem{claim}[definition]{Твърдение}
\newtheorem{axiom}[definition]{Аксиома}
\newtheorem{lemma}[definition]{Лема}
\newtheorem{corollary}[definition]{Следствие}
\theoremstyle{remark}
\newtheorem*{remark}{Забележка}
\newtheorem{problem}{Задача}
\newtheorem{solution}{Решение}
\theoremstyle{definition}

\setlength\parindent{0pt}

\title{Въведение в алгоритмите и асимптотичния анализ}
\author{Тодор Дуков}
\date{}

\begin{document}
\maketitle

\section*{Що е то алгоритъм?}

Алгоритмите се срещат навсякъде около нас:
\begin{itemize}
  \item рецептите са алгоритми за готвене
  \item сутрешното приготвяне
  \item придвижването от точка A до точка B
  \item търсенето на книга в библиотеката
\end{itemize}

Въпреки това е трудно да се даде формална дефиниция на това какво точно е алгоритъм.
На ниво интуиция, човек може да си мисли, че това просто е някакъв последователен списък от стъпки/инструкции, които човек/машина трябва да изпълни.
Други начини човек да си мисли за алгоритмите, са:
\begin{itemize}
  \item програми -- обикновено така се реализират алгоритми
  \item машини на Тюринг, крайни (стекови) автомати или формални граматики
  \item частично рекурсивни функции
\end{itemize}

Един програмист в ежедневието си постоянно пише алгоритми за да решава различни задачи/проблеми.
Една задача може да се решава по много начини, някои по-добри от други.
Добрият програмист, освен че ще намери решение на проблема, той ще намери най-доброто решение (или поне достатъчно добро за неговите цели).

\section*{Какво означава добро решение?}

Хубаво е човек да се води по следните (неизчерпателни) критерии:
\begin{itemize}
  \item решението трябва да е коректно -- ако алгоритъма работи само през 50\% от времето, най-вероятно можем да се справим по-добре
  \item решението трябва да е бързо -- ако алгоритъма ще завърши работа след като всички звезди са измрели, то той практически не ни върши работа
  \item решението трябва да заема малко памет -- ако алгоритъма по-време на своята работа се нуждае от повече памет, колкото компютъра може да предостави, за наз този алгоритъм е безполезен
  \item решението трябва да е просто -- това е може би най-маловажния критерии от тези, но въпреки това е хубаво когато човек може, да пише чист и разбираем код, който лесно се разширява
\end{itemize}

За да можем да сравняваме алгоритми в зависимост от това колко големи ресурси (време и памет) използват, трябва първо да можем да квантифицираме тези ресурси.

\section*{Как квантифицираме времето и паметта?}

Когато пишем алгоритми, имаме няколко базови инструкции (за които предварително сме се уговорили), които ще наричаме \textbf{атомарни инструкции}.
Тяхното извикване ще отнеме една единица време.
\textbf{Време за изпълнение} ще наричаме броят на извикванията на атомарните инструкции по време на изпълнение на програмата.
Също така числата и символите ще бъдат нашите \textbf{атомарни типове данни}, и ще заемат една единица памет.
\textbf{Паметта}, която една програма заема, ще наричаме максималния брой на единици от атомарни типове данни по-време на изпълнение, без да броим входните данни.
Обикновено времето и паметта зависят от размера на подадените входни данни.
Това означава, че можем да си мислим за времето и паметта като функции на размера на входа.
Подхода, който ще изберем, е да сравняваме функциите за време/памет на различните алгоритми асимптотично.
Интересуваме се не толкова от конкретните стойности, а от поведението им когато вървим към безкрайността.

\section*{Няколко дефиниции}
\footnotetext[1]{точност до константен множител}
Множеството от функции, които ще анализираме е $\F = \{ f \mid f : \N \rightarrow \R^{\geq 0} \}$.
За всяка функция $f \in \F$ ще дефинираме следните пет множества:
\begin{itemize}
  \item $\Theta(f) = \{ g \in \F \: \mid (\exists c_1 > 0)(\exists c_2 > 0)(\exists n_0 \in \N)(\forall n \geq n_0)(c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n))\}$ \\
    Може да тълкуваме $\Theta(f)$ като множеството от функциите, които растат\footnotemark[1] толкова бързо, колкото $f$.
    Можем да вземем за пример $f(n) = n + 200$ и $g(n) = 3n + 1$:

    \begin{tikzpicture}
      \begin{axis}[axis lines = left, xlabel = \(n\), ylabel = {\(h(n)\)}]
        \addplot[domain = 0:1000, color=red]{x+200};
        \addlegendentry{$f(n)$};
        \addplot[domain = 0:1000, color=blue]{(3*x)+1};
        \addlegendentry{$g(n) (c_2 = 1)$};
        \addplot[domain = 0:1000, color=green]{((3*x)+1)/4};
        \addlegendentry{$\frac{1}{4} \cdot g(n) (c_1 = \frac{1}{4})$};
      \end{axis}
    \end{tikzpicture}

    На картинката се вижда как от един момент нататък, функцията $f$ остава ``заключена`` между $c_1 \cdot g$ и $c_2 \cdot g$.
    Вместо да пишем $g \in \Theta(f)$, ще пишем $g = \Theta(f)$ или $g \asymp f$.
  \item $O(f) = \{ g \in \F \: \mid (\exists c > 0)(\exists n_0 \in \N)(\forall n \geq n_0)(f(n) \leq c \cdot g(n))\}$ \\
    Може да тълкуваме $O(f)$ като множеството от функциите, които не растат\footnotemark[1] по-бързо от $f$.
    Тук заслабваме условията от $\Theta(f)$ като искаме само горната граница.
    Нека вземем за пример $f(n) = n$ и $g(n) = n^2$:

    \begin{tikzpicture}
      \begin{axis}[axis lines = left, xlabel = \(n\), ylabel = {\(h(n)\)}]
        \addplot[domain = 0:10, color=red]{x};
        \addlegendentry{$f(n)$};
        \addplot[domain = 0:10, color=blue]{x*x};
        \addlegendentry{$g(n)$};
      \end{axis}
    \end{tikzpicture}

    Вместо да пишем $g \in O(f)$, ще пишем $g = O(f)$ или $g \preceq f$.
  \item $o(f) = \{ g \in \F \: \mid (\forall c > 0)(\exists n_0 \in \N)(\forall n \geq n_0)(f(n) < c \cdot g(n))\}$ \\
    Може да тълкуваме $o(f)$ като множеството от функциите, които растат\footnotemark[1] по-бавно от $f$.
    Разликата между $O(f)$ и $o(f)$ е строгото неравенство.
    Лесно се вижда, че $o(f) \subseteq O(f)$.
    Тук изключваме функциите от същия порядък.
    Вместо да пишем $g \in o(f)$, ще пишем $g = o(f)$ или $g \prec f$.
  \item $\Omega(f) = \{ g \in \F \: \mid (\exists c > 0)(\exists n_0 \in \N)(\forall n \geq n_0)(c \cdot g(n) \leq f(n))\}$ \\
    Може да тълкуваме $\Omega(f)$ като множеството от функциите, които не растат\footnotemark[1] по-бавно от $f$.
    Това е дуалното множество на $O(f)$.
    Вместо да пишем $g \in \Omega(f)$, ще пишем $g = \Omega(f)$ или $g \succeq f$.
  \item $\omega(f) = \{ g \in \F \: \mid (\forall c > 0)(\exists n_0 \in \N)(\forall n \geq n_0)(c \cdot g(n) < f(n))\}$ \\
    Може да тълкуваме $\omega(f)$ като множеството от функциите, които растат\footnotemark[1] по-бързо от $f$.
    Това е дуалното множество на $o(f)$.
    Вместо да пишем $g \in \omega(f)$, ще пишем $g = \omega(f)$ или $g \succ f$.
\end{itemize}

\section*{Няколко полезни свойства}

Тук ще видим няколко свойства, които много често се ползват в задачите:
\begin{itemize}
  \item Нека $f, g \in \F$ и $\lim\limits_{n \rightarrow \infty} \frac{f(n)}{g(n)} = l$
    Тогава ако $l = 0$, то $f \prec g$, ако $l = \infty$, то $f \succ g$, и в противен случай $f \asymp g$
  \item $f + g \asymp \max\{f, g\}$ за всяко $f, g \in \F$
  \item $c \cdot f \asymp f$ за всяко $f \in F$ и $c > 0$
  \item $f \asymp g \iff f^c \asymp g^c$ за всяко $f, g \in F$ и $c > 0$
  \item $O(f) \cap \Omega(f) = \Theta(f)$ за всяко $f \in \F$
  \item $o(f) \cap \omega(f) = O(f) \cap \omega(f) = o(f) \cap \Omega(f) = \varnothing$ за всяко $f \in \F$
  \item $f \prec g \iff g \succ f$ и $f \preceq g \iff g \succeq f$ за всяко $f, g \in \F$
  \item ако $f \prec g$, то $c^f \prec c^g$ за всяко $f, g \in \F$ и $c > 1$
  \item ако $\log(f) \prec \log(g)$, то $f \prec g$ за всяко $f, g \in \F$ и $c > 1$
  \item ако $c^f \asymp c^g$, то $f \asymp g$ за всяко $f, g \in \F$ и $c > 1$
  \item ако $f \asymp g$, то $\log(f) \asymp \log(g)$ за всяко $f, g \in \F$ и $c > 1$
  \item $n! \asymp \sqrt{n} \frac{n^n}{e^n}$ - апроксимация на Stirling
  \item $\log(n!) \asymp n \log(n)$
  \item $\log(n) \prec n^k \prec 2^n \prec n! \prec n^n \prec 2^{n^2}$ за всяко $k \geq 1$
\end{itemize}

\section*{Задачи}

\begin{problem}
  Да се сравнят асимптотично следните двойки функции:
  \begin{enumerate}
    \item $f(n) = \log(\log(n))$ и $g(n) = \log(n)$
    \item $f(n) = 5n^3$ и $g(n) = n \sqrt{n^9 + n^5}$
    \item $f(n) = n 5^n$ и $g(n) = n^ 2 3^n$
    \item $f(n) = n^n$ и $g(n) = 3^{n^2}$
    \item $f(n) = 3^{n^2}$ и $g(n) = 2^{n^3}$
  \end{enumerate}
\end{problem}

\begin{problem}
  Да се докаже, че $\sum\limits_{i = 0}^n i^k \asymp n^{k+1}$
\end{problem}

\begin{problem}
  Да се подредят по асимптотично нарастване следните функции:
  \begin{align*}
    f_1(n) &= n^2 &f_2(n) &= \sqrt{n} &f_3(n) &= \log^2(n) &f_4(n) &= \sqrt{\log(n)!} \\
    f_5(n) &= \sum\limits_{k = 2}^{\log(n)} \frac{1}{k} &f_6(n) &= \log(\log(n)) &f_7(n) &= 2^{2^{\sqrt{n}}} &f_8(n) &= \binom{\binom{n}{3}}{2} \\
    f_9(n) &=2^{n^2} &f_{10}(n) &= 3^{n \sqrt{n}} &f_{11}(n) &=2^{\binom{n}{2}} &f_{12}(n) &= \sum\limits_{k = 1}^{n^2} \frac{1}{2^k}
  \end{align*}
\end{problem}

\end{document}
